apiVersion: apps.kubermatic.k8c.io/v1
kind: ApplicationInstallation
metadata:
  labels:
    apps.kubermatic.k8c.io/managed-by: kkp
    apps.kubermatic.k8c.io/type: cni
  name: cilium
  namespace: kube-system
spec:
  applicationRef:
    name: cilium
    version: 1.14.16
  deployOptions:
    helm:
      atomic: true
      timeout: 10m0s
      wait: true
  namespace:
    create: false
    name: kube-system
  reconciliationInterval: 0h10m0s
  valuesBlock: |
    certgen:
      podSecurityContext:
        seccompProfile:
          type: RuntimeDefault
    ##### mod - Mesh Setup
    cluster:
      id: 1
      name: cluster-1
    clustermesh:
      apiserver:
        service:
          type: LoadBalancer
          annotations:
            service.beta.kubernetes.io/aws-load-balancer-internal: "true"
            service.beta.kubernetes.io/aws-load-balancer-type: nlb
        tls:
          auto:
            method: cronJob
          ###### Mesh Setup Step 2
          #ca:
          #  # ca.crt from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
          #  cert: "<base64-encoded-cert>"
          #  # ca.key from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
          #  key: "<base64-encoded-key>"
      config:
        enabled: true
        ###### Mesh Setup Step 2
        #clusters:
        #  - name: cluster-2
        #    address: ""
        #    port: 2379
        #    ips:
        #      # external-ip of the clustermesh-apiserver svc in Cluster 2
        #      - <ip-address>
        #    tls:
        #      # tls.crt from clustermesh-apiserver-remote-cert secret in Cluster 2
        #      cert: "<base64-encoded-cert>"
        #      # tls.key from clustermesh-apiserver-remote-cert secret in Cluster 2
        #      key: "<base64-encoded-key>"
      useAPIServer: true
    ##### mod
    cni:
      exclusive: false
    envoy:
      enabled: false
      podSecurityContext:
        seccompProfile:
          type: RuntimeDefault
    hubble:
      relay:
        enabled: true
        podSecurityContext:
          seccompProfile:
            type: RuntimeDefault
      tls:
        auto:
          method: cronJob
      ui:
        backend: {}
        enabled: true
        frontend: {}
        securityContext:
          enabled: true
          seccompProfile:
            type: RuntimeDefault
    ipam:
      operator:
        clusterPoolIPv4MaskSize: 24
        clusterPoolIPv4PodCIDRList:
        - 172.25.0.0/16 #IMPORTANT NEEDS TO BE DIFFERENT AS IN CLUSTER 2
    ##### k8sServiceHost: ___TODO__REPLACE__WITH_K8S_API_HOST
    k8sServiceHost: bcqd8rwjbn.shared-seed.latest.snapshots.k8c.io
    k8sServicePort: 6443
    kubeProxyReplacement: "true"
    operator:
      podSecurityContext:
        seccompProfile:
          type: RuntimeDefault
      replicas: 1
      securityContext:
        seccompProfile:
          type: RuntimeDefault
    podSecurityContext:
      seccompProfile:
        type: RuntimeDefault
